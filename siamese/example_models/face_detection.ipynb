{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Conv2D, Convolution2D, Flatten, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import ipyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('c:/code/jupyter-notebook/meta-learning/siamese')\n",
    "\n",
    "def read_image(filename, byteorder='>'):\n",
    "    image = Image.open(filename).convert('L')\n",
    "    return image\n",
    "    # with open(filename, 'rb') as f:\n",
    "    #     buffer = f.read()\n",
    "    #\n",
    "    # header, width, height, maxval = re.search(\n",
    "    #     b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "    #     b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "    #     b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "    #     b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    #\n",
    "    # return np.frombuffer(\n",
    "    #     buffer,\n",
    "    #     dtype='u1' if int(maxval) < 256 else byteorder + 'u2',\n",
    "    #     count=int(width) * int(height),\n",
    "    #     offset=len(header)\n",
    "    # ).reshape((int(height), int(width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560, 1920)\n"
     ]
    }
   ],
   "source": [
    "image = read_image('./data/orl_faces/s41/7.pgm')\n",
    "print(np.array(image).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "size = 2\n",
    "total_sample_size = 10000\n",
    "\n",
    "\n",
    "def get_data(size, total_sample_size):\n",
    "    #read the image\n",
    "    image = np.array(read_image('data/orl_faces/s1/1.pgm', 'rw+'))\n",
    "    image = image[::size, ::size]\n",
    "    dims1 = image.shape[0]\n",
    "    dims2 = image.shape[1]\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    genuine_x = np.zeros([total_sample_size, 2, dims1, dims2, 1])\n",
    "    genuine_y = np.zeros([total_sample_size, 1])\n",
    "\n",
    "    for i in range(42):\n",
    "        for j in range(int(total_sample_size/42)):\n",
    "            idx1 = idx2 = 0\n",
    "\n",
    "            while idx1 == idx2:\n",
    "                idx1 = np.random.randint(10)\n",
    "                idx2 = np.random.randint(10)\n",
    "\n",
    "            image1 = read_image(f'data/orl_faces/s{i+1}/{idx1+1}.pgm', 'rw+')\n",
    "            image2 = read_image(f'data/orl_faces/s{i+1}/{idx2+1}.pgm', 'rw+')\n",
    "\n",
    "            image1 = np.array(image1.resize((46, 56)))\n",
    "            image2 = np.array(image2.resize((46, 56)))\n",
    "\n",
    "            genuine_x[count, 0, :, :, 0] = image1\n",
    "            genuine_x[count, 1, :, :, 0] = image2\n",
    "\n",
    "            genuine_y[count] = 1\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    imposter_x = np.zeros([total_sample_size, 2, dims1, dims2, 1])\n",
    "    imposter_y = np.zeros([total_sample_size, 1])\n",
    "\n",
    "    for i in range(int(total_sample_size/10)):\n",
    "        for j in range(10):\n",
    "            idx1 = idx2 = 0\n",
    "\n",
    "            while idx1 == idx2:\n",
    "                idx1 = np.random.randint(42)\n",
    "                idx2 = np.random.randint(42)\n",
    "\n",
    "            image1 = read_image(f'data/orl_faces/s{idx1+1}/{j+1}.pgm', 'rw+')\n",
    "            image2 = read_image(f'data/orl_faces/s{idx2+1}/{j+1}.pgm', 'rw+')\n",
    "\n",
    "            image1 = np.array(image1.resize((46, 56)))\n",
    "            image2 = np.array(image2.resize((46, 56)))\n",
    "\n",
    "            imposter_x[count, 0, :, :, 0] = image1\n",
    "            imposter_x[count, 1, :, :, 0] = image2\n",
    "\n",
    "            imposter_y[count] = 0\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    X = np.concatenate([genuine_x, imposter_x], axis=0)/255\n",
    "    Y = np.concatenate([genuine_y, imposter_y], axis=0)\n",
    "\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2, 56, 46, 1)\n",
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_data(size, total_sample_size)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "x_train, x_text, y_train, y_test = train_test_split(X, Y, test_size=.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def build_network(input_shape):\n",
    "    seq = Sequential()\n",
    "\n",
    "    nb_filter = [6, 12]\n",
    "    kernel_size = 3\n",
    "\n",
    "    seq.add(Conv2D(nb_filter[0], (kernel_size, kernel_size),\n",
    "                   input_shape=input_shape, padding='valid', data_format='channels_last'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPool2D(pool_size=(2,2)))\n",
    "    seq.add(Dropout(.25))\n",
    "\n",
    "    seq.add(Conv2D(nb_filter[1], (kernel_size, kernel_size),\n",
    "                   input_shape=input_shape, padding='valid', data_format='channels_last'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPool2D(pool_size=(2,2)))\n",
    "    seq.add(Dropout(.25))\n",
    "\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, 'relu'))\n",
    "    seq.add(Dropout(.1))\n",
    "    seq.add(Dense(50, 'relu'))\n",
    "\n",
    "    return seq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)\n",
    "\n",
    "base_network = build_network(input_dim)\n",
    "network_a = base_network(img_a)\n",
    "network_b = base_network(img_b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    vect1, vect2 = vects\n",
    "    return K.sqrt(K.sum(K.square(vect1 - vect2), axis=1, keepdims=True))\n",
    "\n",
    "def euclid_shape(shape):\n",
    "    shape1, shape2 = shape\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "distance = Lambda(euclidean_distance, euclid_shape)([network_a, network_b])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "epochs = 13\n",
    "rms = RMSprop()\n",
    "\n",
    "model = Model(inputs=[img_a, img_b], outputs=distance)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1- y_true)*K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "WARNING:tensorflow:From C:\\Users\\consi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1629s vs `on_train_batch_end` time: 0.3065s). Check your callbacks.\n",
      "88/88 - 29s - loss: 0.1879 - val_loss: 0.2543\n",
      "Epoch 2/13\n",
      "88/88 - 19s - loss: 0.1168 - val_loss: 0.2060\n",
      "Epoch 3/13\n",
      "88/88 - 19s - loss: 0.0845 - val_loss: 0.1003\n",
      "Epoch 4/13\n",
      "88/88 - 18s - loss: 0.0650 - val_loss: 0.0713\n",
      "Epoch 5/13\n",
      "88/88 - 20s - loss: 0.0544 - val_loss: 0.0513\n",
      "Epoch 6/13\n",
      "88/88 - 19s - loss: 0.0468 - val_loss: 0.0459\n",
      "Epoch 7/13\n",
      "88/88 - 18s - loss: 0.0424 - val_loss: 0.0431\n",
      "Epoch 8/13\n",
      "88/88 - 18s - loss: 0.0383 - val_loss: 0.0329\n",
      "Epoch 9/13\n",
      "88/88 - 17s - loss: 0.0348 - val_loss: 0.0275\n",
      "Epoch 10/13\n",
      "88/88 - 19s - loss: 0.0320 - val_loss: 0.0224\n",
      "Epoch 11/13\n",
      "88/88 - 18s - loss: 0.0298 - val_loss: 0.0183\n",
      "Epoch 12/13\n",
      "88/88 - 17s - loss: 0.0275 - val_loss: 0.0210\n",
      "Epoch 13/13\n",
      "88/88 - 18s - loss: 0.0264 - val_loss: 0.0161\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x20e0af5af70>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1 = x_train[:, 0]\n",
    "img_2 = x_train[:, 1]\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"log/{}\".format(time()))\n",
    "model.fit([img_1, img_2], y_train, validation_split=.25,\n",
    "          batch_size=128, verbose=2, epochs=epochs, callbacks=[tensorboard])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9689655172413794"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict([x_text[:, 0], x_text[:, 1]])\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "compute_accuracy(pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def compare_face(face_1, face_2):\n",
    "    size = 2\n",
    "    idx1 = idx2 = 0\n",
    "    while idx1==idx2:\n",
    "        idx1 = np.random.randint(10)\n",
    "        idx2 = np.random.randint(10)\n",
    "\n",
    "    img_1 = read_image(f'data/orl_faces/s{face_1+1}/{idx1+1}.pgm')\n",
    "    img_2 = read_image(f'data/orl_faces/s{face_2+1}/{idx2+1}.pgm')\n",
    "\n",
    "    img_1 = img_1.resize((46, 56))\n",
    "    img_2 = img_2.resize((46, 56))\n",
    "\n",
    "    img_1.show()\n",
    "    img_2.show()\n",
    "\n",
    "    img_1 = np.array(img_1)\n",
    "    img_2 = np.array(img_2)\n",
    "\n",
    "    dim1, dim2 = img_1.shape\n",
    "    test_data = np.zeros([1, 2, dim1, dim2, 1])\n",
    "    test_y = np.zeros([1, 1])\n",
    "\n",
    "    test_data[0, 0, :, :, 0] = img_1\n",
    "    test_data[0, 1, :, :, 0] = img_2\n",
    "    test_y[0, :] = face_1 == face_2\n",
    "\n",
    "    pred = model.predict([test_data[:, 0], test_data[:,1]])\n",
    "\n",
    "    print(pred)\n",
    "    print(idx1, idx2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.283669]]\n",
      "4 0\n"
     ]
    }
   ],
   "source": [
    "compare_face(40, 40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}